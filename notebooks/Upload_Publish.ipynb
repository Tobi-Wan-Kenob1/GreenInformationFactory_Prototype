{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "70ea272f-d16d-4d68-99c1-71565bf330bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, glob, requests\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "import re, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9bbf48-533a-4b72-886d-e6cb79121073",
   "metadata": {},
   "source": [
    "# Create the deposition on Zenodo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8d671c2-77c2-452a-84d6-8c1bd0d09534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pathlib, subprocess\n",
    "\n",
    "root = pathlib.Path.cwd()  # project root if you launched Jupyter from there\n",
    "payload = root / \"release_payload\"\n",
    "payload.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de558767-a046-4e78-a84e-3aaf314f9e7b",
   "metadata": {},
   "source": [
    "## Define what files to upload (Used and processed training data + model + plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d42879-bff4-439c-a467-e2b67d8211d3",
   "metadata": {},
   "source": [
    "### Collect everything to upload and within the **release_payload** directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "288a6831-b43d-49d5-9efb-dc0294f58a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect artifacts (adjust if some are optional)\n",
    "sources = [\n",
    "    root / \"../data/processed/Train/BioFairNet_Pilot1_Testrun_Train_in.csv\",\n",
    "    root / \"../data/processed/Train/BioFairNet_Pilot1_Testrun_Train_out.csv\",\n",
    "    root / \"../data/processed/Test/BioFairNet_Pilot1_Testrun_Test_in.csv\",\n",
    "    root / \"../data/processed/Test/BioFairNet_Pilot1_Testrun_Test_out.csv\",\n",
    "    root / \"../data/results/lr_evaluation.csv\",\n",
    "    root / \"../models/final_model.pkl\",              \n",
    "    root / \"../data/results/lr_evaluation.png\",       # optional\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d8ace23f-93c1-4bc8-8fa3-72e9b5e6b6ad",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Payload now contains:\n",
      "  - BioFairNet_Pilot1_Testrun_Test_in.csv\n",
      "  - BioFairNet_Pilot1_Testrun_Test_out.csv\n",
      "  - BioFairNet_Pilot1_Testrun_Train_in.csv\n",
      "  - BioFairNet_Pilot1_Testrun_Train_out.csv\n",
      "  - all_modelsTestrun_Pilot1.pkl\n",
      "  - lr_evaluation.csv\n",
      "  - lr_predictions_plot.png\n"
     ]
    }
   ],
   "source": [
    "def find_repo_root(start: Path = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for parent in [p, *p.resolve().parents]:\n",
    "        if (parent / \".git\").exists():\n",
    "            return parent\n",
    "    return Path.cwd()\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "payload = repo_root / \"notebooks\" / \"release_payload\"\n",
    "payload.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Define sources RELATIVE TO REPO ROOT (no '../')\n",
    "rel_sources = [\n",
    "    \"data/processed/Train/BioFairNet_Pilot1_Testrun_Train_in.csv\",\n",
    "    \"data/processed/Train/BioFairNet_Pilot1_Testrun_Train_out.csv\",\n",
    "    \"data/processed/Test/BioFairNet_Pilot1_Testrun_Test_in.csv\",\n",
    "    \"data/processed/Test/BioFairNet_Pilot1_Testrun_Test_out.csv\",\n",
    "    \"data/results/lr_evaluation.csv\",\n",
    "    \"data/results/lr_predictions_plot.png\",\n",
    "    \"notebooks/models/all_modelsTestrun_Pilot1.pkl\"        \n",
    "]\n",
    "sources = [repo_root / p for p in rel_sources]\n",
    "\n",
    "missing = []\n",
    "copied = []\n",
    "for src in sources:\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, payload / src.name)\n",
    "        copied.append(src.name)\n",
    "    else:\n",
    "        missing.append(src.as_posix())\n",
    "\n",
    "print(\"‚úÖ Payload now contains:\")\n",
    "for p in sorted([f.name for f in payload.iterdir() if f.is_file()]):\n",
    "    print(\"  -\", p)\n",
    "\n",
    "if missing:\n",
    "    print(\"\\n‚ö†Ô∏è These files were NOT found and were skipped:\")\n",
    "    for m in missing:\n",
    "        print(\"  -\", m)\n",
    "    print(\"\\nTip: verify the filenames/locations. For example, your figure might be \"\n",
    "          \"`figures/model_performance.png` not `data/results/lr_evaluation.png`, \"\n",
    "          \"and `models/final_model.pkl` must be saved before copying.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cf2e1abf-f023-4b08-8d8a-dfb2ae88de8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "zenodo_params = {\n",
    "    \"title\": \"GreenInformationFactory - BioFairNet_Pilot1_Testrun_Adapted\",\n",
    "    \"description\": \"Train/test splits, trained model, and evaluation figure generated by the GreenInformationFactory pipeline. Raw data: 10.5281/zenodo.16256961.\",\n",
    "    \"community\": \"biofairnet\",\n",
    "    \"creator\": \"Tobias Rosnitschek\",\n",
    "    \"affiliation\": \"University of Bayreuth\",\n",
    "    \"orcid\": \"0000-0002-4876-2536\",\n",
    "    \"keywords\": [\"FAIR\", \"machine learning\", \"circular economy\"],\n",
    "    \"license\": \"MIT\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b4bbd87d-cfe0-4482-bbbb-05c2667e1bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Parameters captured and saved.\n",
      "üìÑ Saved to: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/metadata/zenodo_params.json\n",
      "\n",
      "{\n",
      "  \"title\": \"GreenInformationFactory - BioFairNet_Pilot1_Testrun_Adapted\",\n",
      "  \"description\": \"Train/test splits, trained model, and evaluation figure generated by the GreenInformationFactory pipeline. Raw data: 10.5281/zenodo.16256961.\",\n",
      "  \"community\": \"biofairnet\",\n",
      "  \"creator\": \"Tobias Rosnitschek\",\n",
      "  \"affiliation\": \"University of Bayreuth\",\n",
      "  \"orcid\": \"0000-0002-4876-2536\",\n",
      "  \"keywords\": [\n",
      "    \"FAIR\",\n",
      "    \"machine learning\",\n",
      "    \"circular economy\"\n",
      "  ],\n",
      "  \"license\": \"MIT\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Save so later cells (e.g., workflow writer / trigger) can reuse without re-prompting\n",
    "config_path = Path(\"../metadata/zenodo_params.json\")\n",
    "config_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "config_path.write_text(json.dumps(zenodo_params, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n‚úÖ Parameters captured and saved.\")\n",
    "print(f\"üìÑ Saved to: {config_path.resolve()}\\n\")\n",
    "print(json.dumps(zenodo_params, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4cb83eda-0703-4c77-a056-a44b0e1d9bcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wrote workflow to: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/.github/workflows/greeninformationfactory-biofairnet-pilot1-testrun-adapted-zenodo-upload.yml\n",
      "‚ÑπÔ∏è Reminder: if you want these defaults when running from GitHub ‚Üí Actions, keep this file committed.\n"
     ]
    }
   ],
   "source": [
    "def find_repo_root(start: Path = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for parent in [p, *p.resolve().parents]:\n",
    "        if (parent / \".git\").exists():\n",
    "            return parent\n",
    "    return Path.cwd()\n",
    "\n",
    "def slugify(s: str) -> str:\n",
    "    s = s.strip().lower()\n",
    "    s = re.sub(r\"[^a-z0-9]+\", \"-\", s)\n",
    "    s = re.sub(r\"-+\", \"-\", s).strip(\"-\")\n",
    "    return s[:60]  # keep filename manageable\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "params_path = repo_root / \"metadata\" / \"zenodo_params.json\"\n",
    "tpl_path    = repo_root / \"helper\" / \"zenodo-upload-template.yml\"\n",
    "out_dir     = repo_root / \".github\" / \"workflows\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Load params\n",
    "assert params_path.exists(), f\"Params file not found: {params_path}\"\n",
    "zenodo_params = json.loads(params_path.read_text(encoding=\"utf-8\"))\n",
    "\n",
    "# Load template\n",
    "assert tpl_path.exists(), f\"Template not found: {tpl_path}\"\n",
    "tpl = tpl_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Fill placeholders\n",
    "kw = (zenodo_params.get(\"keywords\") or []) + [\"\", \"\", \"\"]\n",
    "filled = (tpl.replace(\"__TITLE__\",        zenodo_params[\"title\"])\n",
    "            .replace(\"__DESCRIPTION__\",   zenodo_params[\"description\"])\n",
    "            .replace(\"__COMMUNITY__\",     zenodo_params[\"community\"])\n",
    "            .replace(\"__CREATOR__\",       zenodo_params[\"creator\"])\n",
    "            .replace(\"__AFFILIATION__\",   zenodo_params[\"affiliation\"])\n",
    "            .replace(\"__ORCID__\",         zenodo_params.get(\"orcid\",\"\"))\n",
    "            .replace(\"__KW1__\",           kw[0])\n",
    "            .replace(\"__KW2__\",           kw[1])\n",
    "            .replace(\"__KW3__\",           kw[2])\n",
    "            .replace(\"__LICENSE__\",       zenodo_params[\"license\"])\n",
    "         )\n",
    "\n",
    "# Write output\n",
    "slug = slugify(zenodo_params[\"title\"])\n",
    "out_path = out_dir / f\"{slug}-zenodo-upload.yml\"\n",
    "\n",
    "if out_path.exists():\n",
    "    resp = input(f\"‚ö†Ô∏è {out_path.name} exists. Overwrite? [y/N]: \").strip().lower()\n",
    "    if resp not in (\"y\", \"yes\"):\n",
    "        print(\"‚ùå Aborted. Existing workflow left unchanged.\")\n",
    "        sys.exit(0)\n",
    "\n",
    "out_path.write_text(filled, encoding=\"utf-8\")\n",
    "print(f\"‚úÖ Wrote workflow to: {out_path}\")\n",
    "print(\"‚ÑπÔ∏è Reminder: if you want these defaults when running from GitHub ‚Üí Actions, keep this file committed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aafcc4-7b0f-4b41-ad7b-b524cfd48fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import subprocess, shlex\n",
    "\n",
    "keep = \"greeninformationfactory-biofairnet-pilot1-testrun-adapted-zenodo-upload.yml\"  # change to the one you want to keep\n",
    "wf_dir = Path(\".github/workflows\")\n",
    "assert wf_dir.exists(), \"No .github/workflows directory found.\"\n",
    "\n",
    "to_delete = [p for p in wf_dir.glob(\"*.yml\") if p.name != keep]\n",
    "if not to_delete:\n",
    "    print(\"Nothing to delete.\")\n",
    "else:\n",
    "    for p in to_delete:\n",
    "        print(\"Deleting\", p)\n",
    "        p.unlink()\n",
    "\n",
    "    subprocess.run(shlex.split(\"git add -A\"), check=True)\n",
    "    subprocess.run(shlex.split('git commit -m \"Clean workflows: keep only %s\"' % keep), check=True)\n",
    "    subprocess.run(shlex.split(\"git push origin main\"), check=True)\n",
    "    print(\"‚úÖ Cleaned and pushed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ce2d5276-2f08-446a-b020-37bda651797d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ git add -f release_payload\n",
      "$ git add /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/.github/workflows/greeninformationfactory-biofairnet-pilot1-testrun-adapted-zenodo-upload.yml\n",
      "$ git commit -m \"Add Zenodo upload workflow generated from template\"\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "Changes not staged for commit:\n",
      "  (use \"git add <file>...\" to update what will be committed)\n",
      "  (use \"git restore <file>...\" to discard changes in working directory)\n",
      "\tmodified:   ../helper/zenodo-upload-template.yml\n",
      "\tmodified:   ../metadata/zenodo_params.json\n",
      "\tmodified:   Train_and_Optimize_Model-Copy1.ipynb\n",
      "\tmodified:   Upload_Publish.ipynb\n",
      "\n",
      "no changes added to commit (use \"git add\" and/or \"git commit -a\")\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['git', 'commit', '-m', 'Add Zenodo upload workflow generated from template']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cmd \u001b[38;5;129;01min\u001b[39;00m cmds:\n\u001b[32m     15\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m$\u001b[39m\u001b[33m\"\u001b[39m, cmd)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m     \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshlex\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m‚úÖ Pushed workflow and payload.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     18\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mNext: Trigger via GitHub ‚Üí Actions ‚Üí Run workflow (pick this file), or push a tag like zenodo-YYYYMMDD-HHMM.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/greeninfo/lib/python3.11/subprocess.py:571\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    569\u001b[39m     retcode = process.poll()\n\u001b[32m    570\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    572\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    573\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['git', 'commit', '-m', 'Add Zenodo upload workflow generated from template']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "import subprocess, shlex, pathlib\n",
    "\n",
    "# ensure release_payload exists and has files before forcing add\n",
    "payload = pathlib.Path(\"release_payload\")\n",
    "if not payload.exists() or not any(payload.iterdir()):\n",
    "    print(\"‚ö†Ô∏è release_payload is empty or missing. Create/populate it before pushing.\")\n",
    "else:\n",
    "    cmds = [\n",
    "        \"git add -f release_payload\",\n",
    "        f\"git add {out_path.as_posix()}\",\n",
    "        'git commit -m \"Add Zenodo upload workflow generated from template\"',\n",
    "        \"git push origin main\",\n",
    "    ]\n",
    "    for cmd in cmds:\n",
    "        print(\"$\", cmd)\n",
    "        subprocess.run(shlex.split(cmd), check=True)\n",
    "    print(\"‚úÖ Pushed workflow and payload.\")\n",
    "    print(\"Next: Trigger via GitHub ‚Üí Actions ‚Üí Run workflow (pick this file), or push a tag like zenodo-YYYYMMDD-HHMM.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "4ef6cecc-8793-403d-9cd2-aebebb104f50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['git', 'tag', 'zenodo-2025m19-1219'], returncode=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "tag = \"zenodo-\"+datetime.datetime.now().strftime(\"%Ym%d-%H%M\")\n",
    "subprocess.run(shlex.split(f\"git tag {tag}\"), check = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf0b92e9-3223-4f47-b53f-0471026b4697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pushed tag: zenodo-2025m19-1219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:Tobi-Wan-Kenob1/GreenInformationFactory_Prototype.git\n",
      " * [new tag]         zenodo-2025m19-1219 -> zenodo-2025m19-1219\n"
     ]
    }
   ],
   "source": [
    "subprocess.run(shlex.split(\"git push origin --tags\"), check = True)\n",
    "print(\"Pushed tag:\",tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4f6aa-ff32-47ca-97a9-c3686d35dd89",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-greeninfo",
   "language": "python",
   "name": "conda-env-.conda-greeninfo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
