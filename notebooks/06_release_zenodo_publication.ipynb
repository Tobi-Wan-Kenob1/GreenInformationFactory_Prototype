{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbcb36e3-696c-46ed-b1cd-1684ec9038fd",
   "metadata": {},
   "source": [
    "### Imports + repo paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3791cc25-8a8e-4f47-82e9-8b126d8f6771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Repo root: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype\n",
      "payload_dir: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/notebooks/release_payload\n",
      "meta_dir: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/metadata\n",
      "wf_dir: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/.github/workflows\n"
     ]
    }
   ],
   "source": [
    "import os, json, re, sys, shutil, shlex, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# If you have helper.utils in your repo, use it; otherwise fallback to local finder.\n",
    "def find_repo_root(start: Path = None) -> Path:\n",
    "    p = start or Path.cwd()\n",
    "    for parent in [p, *p.resolve().parents]:\n",
    "        if (parent / \".git\").exists():\n",
    "            return parent\n",
    "    raise RuntimeError(\"No git repo root found (.git not present). Run this inside the repo folder.\")\n",
    "\n",
    "repo_root = find_repo_root()\n",
    "print(\"‚úÖ Repo root:\", repo_root)\n",
    "\n",
    "payload_dir = repo_root / \"notebooks\" / \"release_payload\"\n",
    "meta_dir    = repo_root / \"metadata\"\n",
    "wf_dir      = repo_root / \".github\" / \"workflows\"\n",
    "helper_dir  = repo_root / \"helper\"\n",
    "\n",
    "payload_dir.mkdir(parents=True, exist_ok=True)\n",
    "meta_dir.mkdir(parents=True, exist_ok=True)\n",
    "wf_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"payload_dir:\", payload_dir)\n",
    "print(\"meta_dir:\", meta_dir)\n",
    "print(\"wf_dir:\", wf_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3040a0bd-eff5-488a-852d-dd88c133a386",
   "metadata": {},
   "source": [
    "### Clean payload directory\n",
    "\n",
    "Files will be deleted locally after the upload to avoid glutter on the repo. For now: alawys start clean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca7f38ee-39d9-4263-a7d5-3b10b8a14bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Cleaned payload dir: /home/097e80f6-6687-4e65-aab6-9abf7b887006/GreenInformationFactory_Prototype/notebooks/release_payload\n"
     ]
    }
   ],
   "source": [
    "# Clean payload\n",
    "for p in payload_dir.glob(\"*\"):\n",
    "    if p.is_file():\n",
    "        p.unlink()\n",
    "    elif p.is_dir():\n",
    "        shutil.rmtree(p)\n",
    "\n",
    "print(\"‚úÖ Cleaned payload dir:\", payload_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca14fa2-4fc8-4fa7-a235-4d9f16bab981",
   "metadata": {},
   "source": [
    "Define what goes into the release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "168c3f34-1478-486c-b95c-45380e40f14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì¶ Release payload will include:\n",
      " - data/processed/Train/BioFairNet_Pilot1_Testrun_Train_in.csv\n",
      " - data/processed/Train/BioFairNet_Pilot1_Testrun_Train_out.csv\n",
      " - data/processed/Test/BioFairNet_Pilot1_Testrun_Test_in.csv\n",
      " - data/processed/Test/BioFairNet_Pilot1_Testrun_Test_out.csv\n",
      " - data/results/compare_co2_methods_test_rf.png\n",
      " - data/results/compare_mci_methods_test_rf.png\n",
      " - data/results/compare_methods_correlation_test_rf.png\n",
      " - data/results/dist_co2_test_vs_val_rf.png\n",
      " - data/results/dist_mci_test_vs_val_rf.png\n",
      " - data/results/scenario_co2_Stiring_rf.png\n",
      " - data/results/scenario_co2_time_s_rf.png\n",
      " - data/results/scenario_mci_Stiring_rf.png\n",
      " - data/results/scenario_mci_time_s_rf.png\n",
      " - data/results/scenario_results_oneway_rf.csv\n",
      " - data/results/scenario_sustainable_region_pca_Stiring_rf.png\n",
      " - data/results/scenario_sustainable_region_pca_time_s_rf.png\n",
      " - data/results/scenario_y_pred_Stiring_rf.png\n",
      " - data/results/scenario_y_pred_time_s_rf.png\n",
      " - data/results/sustainability_method_comparison_test_rf.csv\n",
      " - data/results/sustainability_method_comparison_test_vs_val_rf.csv\n",
      " - data/results/sustainability_pca_test_rf.csv\n",
      " - data/results/sustainability_pca_val_rf.csv\n",
      " - data/results/test_vs_validation_shift_summary_rf.csv\n",
      " - data/results/tradeoff_test_vs_validation_pca_rf.png\n",
      " - notebooks/models/all_models.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- Core processed data files ---\n",
    "Files = [\n",
    "    \"data/processed/Train/BioFairNet_Pilot1_Testrun_Train_in.csv\",\n",
    "    \"data/processed/Train/BioFairNet_Pilot1_Testrun_Train_out.csv\",\n",
    "    \"data/processed/Test/BioFairNet_Pilot1_Testrun_Test_in.csv\",\n",
    "    \"data/processed/Test/BioFairNet_Pilot1_Testrun_Test_out.csv\",\n",
    "]\n",
    "\n",
    "# --- Models (you said they are in notebooks/models) ---\n",
    "Models = [\n",
    "    \"notebooks/models/all_models.pkl\",\n",
    "]\n",
    "\n",
    "# --- Automatically collect ALL outputs from Notebooks 04 & 05 ---\n",
    "results_dir = repo_root / \"data\" / \"results\"\n",
    "\n",
    "Results = []\n",
    "\n",
    "# Sustainability evaluation outputs (Notebook 04)\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"sustainability*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"compare_*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"tradeoff*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"dist_*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"test_vs_validation*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"method_comparison*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"correlation*.*\")]\n",
    "\n",
    "# Scenario analysis outputs (Notebook 05)\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"scenario*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"sensitivity*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"response_surface*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"oneway*.*\")]\n",
    "Results += [str(p.relative_to(repo_root)) for p in results_dir.glob(\"twofactor*.*\")]\n",
    "\n",
    "# Remove duplicates & sort\n",
    "Results = sorted(set(Results))\n",
    "\n",
    "# --- Combine everything ---\n",
    "sources = Files + Results + Models\n",
    "\n",
    "print(\"üì¶ Release payload will include:\")\n",
    "for s in sources:\n",
    "    print(\" -\", s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0809a2f9-b53e-462a-acd8-eb22b2100dd7",
   "metadata": {},
   "source": [
    "### Collect all files\n",
    "\n",
    "everything for upload will go into `notebooks/release_payload/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337992a7-c122-4f3a-ad42-af80fd20d048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Copied files:\n",
      "  - BioFairNet_Pilot1_Testrun_Test_in.csv\n",
      "  - BioFairNet_Pilot1_Testrun_Test_out.csv\n",
      "  - BioFairNet_Pilot1_Testrun_Train_in.csv\n",
      "  - BioFairNet_Pilot1_Testrun_Train_out.csv\n",
      "  - all_models.pkl\n",
      "  - compare_co2_methods_test_rf.png\n",
      "  - compare_mci_methods_test_rf.png\n",
      "  - compare_methods_correlation_test_rf.png\n",
      "  - dist_co2_test_vs_val_rf.png\n",
      "  - dist_mci_test_vs_val_rf.png\n",
      "  - scenario_co2_Stiring_rf.png\n",
      "  - scenario_co2_time_s_rf.png\n",
      "  - scenario_mci_Stiring_rf.png\n",
      "  - scenario_mci_time_s_rf.png\n",
      "  - scenario_results_oneway_rf.csv\n",
      "  - scenario_sustainable_region_pca_Stiring_rf.png\n",
      "  - scenario_sustainable_region_pca_time_s_rf.png\n",
      "  - scenario_y_pred_Stiring_rf.png\n",
      "  - scenario_y_pred_time_s_rf.png\n",
      "  - sustainability_method_comparison_test_rf.csv\n",
      "  - sustainability_method_comparison_test_vs_val_rf.csv\n",
      "  - sustainability_pca_test_rf.csv\n",
      "  - sustainability_pca_val_rf.csv\n",
      "  - test_vs_validation_shift_summary_rf.csv\n",
      "  - tradeoff_test_vs_validation_pca_rf.png\n"
     ]
    }
   ],
   "source": [
    "missing = []\n",
    "copied = []\n",
    "\n",
    "for rel in sources:\n",
    "    src = repo_root / rel\n",
    "    if src.exists():\n",
    "        shutil.copy2(src, payload_dir / src.name)\n",
    "        copied.append(src.name)\n",
    "    else:\n",
    "        missing.append(rel)\n",
    "\n",
    "print(\"‚úÖ Copied files:\")\n",
    "for f in sorted(copied):\n",
    "    print(\"  -\", f)\n",
    "\n",
    "if missing:\n",
    "    print(\"\\n‚ö†Ô∏è Missing (not copied):\")\n",
    "    for m in missing:\n",
    "        print(\"  -\", m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe94565-1ceb-4585-bf53-22df28095ef5",
   "metadata": {},
   "source": [
    "### Set Zenodo params\n",
    "\n",
    "`metadata/zenodo_params.json` as single source of truth. This avoids having tons of workflow inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21928d39-936c-43c6-92df-f7ad626bd1cc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Note:</b> Sandbox defaults to true.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a75b440a-4068-44c5-bf5c-b303a6ff2f55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wrote: metadata/zenodo_params.json\n"
     ]
    }
   ],
   "source": [
    "zenodo_params = {\n",
    "    \"use_sandbox\": False,                 # ‚úÖ default safe\n",
    "    \"community\": \"biofairnet\",\n",
    "    \"license\": \"MIT\",\n",
    "    \"upload_type\": \"dataset\",\n",
    "    \"title\": \"GreenInformationFactory ‚Äì Release Payload (Processed Data, Models, Results)\",\n",
    "    \"description\": (\n",
    "        \"Release payload generated by the GreenInformationFactory pipeline. \"\n",
    "        \"Contains processed data splits, trained model bundle, evaluation outputs, \"\n",
    "        \"sustainability proxy results (v1/PCA/assumptions), and scenario analysis artifacts. \"\n",
    "        \"Raw data source: 10.5281/zenodo.16256961.\"\n",
    "    ),\n",
    "    \"creators\": [\n",
    "        {\n",
    "            \"name\": \"Rosnitschek, Tobias\",\n",
    "            \"affiliation\": \"University of Bayreuth\",\n",
    "            \"orcid\": \"0000-0002-4876-2536\"  # optional\n",
    "        }\n",
    "    ],\n",
    "    \"keywords\": [\n",
    "        \"FAIR\", \"machine learning\", \"sustainability assessment\"\n",
    "    ],\n",
    "    \"related_doi\": \"10.5281/zenodo.16256961\",\n",
    "    \"payload_dir\": \"notebooks/release_payload\"\n",
    "}\n",
    "\n",
    "params_path = meta_dir / \"zenodo_params.json\"\n",
    "params_path.write_text(json.dumps(zenodo_params, indent=2), encoding=\"utf-8\")\n",
    "print(\"‚úÖ Wrote:\", params_path.relative_to(repo_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae38eb3-a512-4382-837c-85fe8fb50a80",
   "metadata": {},
   "source": [
    "### Generate the upload workflow from template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "18064ddc-7854-4cd3-b4de-f8be681a93ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Wrote workflow: .github/workflows/greeninformationfactory-release-zenodo-upload.yml\n"
     ]
    }
   ],
   "source": [
    "tpl_path = helper_dir / \"zenodo-upload-template.yml\"\n",
    "assert tpl_path.exists(), f\"Template not found: {tpl_path}\"\n",
    "\n",
    "tpl = tpl_path.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Insert path to params json into workflow\n",
    "filled = tpl.replace(\"__PARAMS_JSON__\", \"metadata/zenodo_params.json\")\n",
    "\n",
    "# Slugged workflow filename\n",
    "slug = \"greeninformationfactory-release-zenodo-upload\"\n",
    "wf_path = wf_dir / f\"{slug}.yml\"\n",
    "\n",
    "wf_path.write_text(filled, encoding=\"utf-8\")\n",
    "print(\"‚úÖ Wrote workflow:\", wf_path.relative_to(repo_root))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c724b168-f14f-4cf9-bbce-ff04b50bfe60",
   "metadata": {},
   "source": [
    "### Git commit params + workflow + payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cfeed2de-8355-466c-83e3-41ed95d2a13a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ git pull --rebase origin main\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "From github.com:Tobi-Wan-Kenob1/GreenInformationFactory_Prototype\n",
      " * branch            main       -> FETCH_HEAD\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "Current branch main is up to date.\n",
      "$ git add notebooks/release_payload metadata/zenodo_params.json .github/workflows\n",
      "$ git commit -m \"chore: prepare Zenodo release payload (sandbox default)\"\n",
      "On branch main\n",
      "Your branch is up to date with 'origin/main'.\n",
      "\n",
      "nothing to commit, working tree clean\n",
      "$ git push origin main\n",
      "‚úÖ Pushed changes to main.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Everything up-to-date\n"
     ]
    }
   ],
   "source": [
    "def run(cmd, check=True):\n",
    "    print(\"$\", cmd)\n",
    "    subprocess.run(shlex.split(cmd), cwd=repo_root, check=check)\n",
    "\n",
    "run(\"git pull --rebase origin main\", check=False)\n",
    "\n",
    "run(\"git add notebooks/release_payload metadata/zenodo_params.json .github/workflows\", check=True)\n",
    "\n",
    "msg = 'chore: prepare Zenodo release payload (sandbox default)'\n",
    "run(f'git commit -m \"{msg}\"', check=False)\n",
    "\n",
    "run(\"git push origin main\", check=False)\n",
    "print(\"‚úÖ Pushed changes to main.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11091f9c-bb65-4979-81fd-d70b014d30f0",
   "metadata": {},
   "source": [
    "### Trigger upload\n",
    "\n",
    "This avoids triggering all actions at onec. Here we use a tag prefix that only the upload workflow istens to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "97756aa2-2340-45fb-93fd-e91fced646f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$ git pull --rebase origin main\n",
      "$ git tag zenodo-ul-release-20260129-075226\n",
      "$ git push origin --tags\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "error: cannot pull with rebase: You have unstaged changes.\n",
      "error: please commit or stash them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Triggered Zenodo upload with tag: zenodo-ul-release-20260129-075226\n",
      "‚û°Ô∏è  Go to GitHub ‚Üí Actions ‚Üí 'Zenodo Upload' run logs.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "To github.com:Tobi-Wan-Kenob1/GreenInformationFactory_Prototype.git\n",
      " * [new tag]         zenodo-ul-release-20260129-075226 -> zenodo-ul-release-20260129-075226\n"
     ]
    }
   ],
   "source": [
    "doi = zenodo_params.get(\"related_doi\", \"10.5281/zenodo.16256961\")\n",
    "ts = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tag = f\"zenodo-ul-release-{ts}\"\n",
    "\n",
    "# ensure uniqueness\n",
    "existing = subprocess.run(shlex.split(\"git tag\"), cwd=repo_root, capture_output=True, text=True).stdout.splitlines()\n",
    "if tag in existing:\n",
    "    tag = f\"{tag}-{datetime.utcnow().strftime('%f')}\"\n",
    "\n",
    "run(\"git pull --rebase origin main\", check=False)\n",
    "run(f\"git tag {tag}\", check=True)\n",
    "run(\"git push origin --tags\", check=True)\n",
    "\n",
    "print(f\"‚úÖ Triggered Zenodo upload with tag: {tag}\")\n",
    "print(\"‚û°Ô∏è  Go to GitHub ‚Üí Actions ‚Üí 'Zenodo Upload' run logs.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281de53e-72d3-4031-ad62-103739b43f90",
   "metadata": {},
   "source": [
    "### Local Clean up\n",
    "\n",
    "We do this since the data is curated on Zenodo, not within the Git Repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1dc2528-385b-4d29-8934-536ccf31a356",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Attention:</b> Run this cell ONLY AFTER you see the Zenodo deposition succeeded in the Actions logs.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb37ac4-be3f-41d9-9d0e-b67e34acd806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: remove local payload after successful upload\n",
    "# (Do this only AFTER you see the Zenodo deposition succeeded in Actions logs.)\n",
    "for p in payload_dir.glob(\"*\"):\n",
    "    if p.is_file():\n",
    "        p.unlink()\n",
    "print(\"‚úÖ Local payload cleaned.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
